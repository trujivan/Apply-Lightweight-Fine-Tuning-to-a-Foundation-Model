{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ca7ee7",
   "metadata": {},
   "source": [
    "##### Vanessa Trujillo \n",
    "##### Submission date 02/18/24\n",
    "##### Udacity Generative AI Nanodegree project: Apply Lightweight Fine-Tuning to a Foundation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5872e",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916f54b",
   "metadata": {},
   "source": [
    "* PEFT technique: The chosen PEFT (Parameter-Efficient Fine-Tuning) technique involves unfreezing all the model parameters after the initial training of the base model. This allows the model to adapt more closely to the task during fine-tuning. The base model is trained for one epoch with frozen parameters and then fine-tuned for an additional two epochs with unfrozen parameters during PEFT.\n",
    "* Model: The base model used is distilbert-base-uncased for sequence classification. The same base model is utilized for both the initial training and the PEFT process.\n",
    "* Evaluation approach: The evaluation is performed using the Trainer class from the Hugging Face transformers library. The evaluation strategy is set to \"epoch,\" meaning evaluation is performed after each training epoch. The evaluation metrics include loss, accuracy, runtime, samples per second, steps per second, and epoch.\n",
    "* Fine-tuning dataset: The fine-tuning dataset is based on the rotten_tomatoes dataset, with train and test splits.  To expedite the example, only a subset of 500 samples from each split is used. The dataset is pre-processed using the distilbert-base-uncased tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f019f7",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bfe559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the train and test splits of the rotten_tomatoes dataset, Attributed to the Udacity course code and Huggingface code snippets.\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset(\"rotten_tomatoes\", split=splits))}\n",
    "\n",
    "# Thin out the dataset to make it run faster for this example\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(500))\n",
    "\n",
    "# Pre-process dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(preprocess_function, batched=True)\n",
    "\n",
    "# Load and set up the base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "for param in base_model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421d2cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 03:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573705</td>\n",
       "      <td>0.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.548210</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "    \n",
    "    \n",
    "# Training the base model, Attributed to the Udacity course code.\n",
    "trainer_base = Trainer(\n",
    "    model=base_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis_base\",\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=6,\n",
    "        per_device_eval_batch_size=6,\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Training the base model\n",
    "trainer_base.train()\n",
    "\n",
    "# Evaluate the base model\n",
    "base_model_evaluation = trainer_base.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a673f4",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c7bf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [168/168 13:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.505375</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.810996</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.897101</td>\n",
       "      <td>0.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.973270</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=168, training_loss=0.19035461970738002, metrics={'train_runtime': 788.9237, 'train_samples_per_second': 2.535, 'train_steps_per_second': 0.213, 'total_flos': 264934797312000.0, 'train_loss': 0.19035461970738002, 'epoch': 4.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Parameter-Efficient Fine-Tuning (PEFT)\n",
    "\n",
    "# Unfreeze all the model parameters.\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Training the PEFT model\n",
    "trainer_peft = Trainer(\n",
    "    model=base_model,  # Use the base model with unfrozen parameters\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis_peft\", # Output directory for saving the PEFT model\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=12,\n",
    "        per_device_eval_batch_size=12,\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_peft.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523e1ce",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70040b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Evaluation:\n",
      "{'eval_loss': 0.548210084438324, 'eval_accuracy': 0.73, 'eval_runtime': 45.873, 'eval_samples_per_second': 10.9, 'eval_steps_per_second': 1.831, 'epoch': 2.0}\n",
      "\n",
      "PEFT Model Evaluation:\n",
      "{'eval_loss': 0.5053754448890686, 'eval_accuracy': 0.776, 'eval_runtime': 42.8268, 'eval_samples_per_second': 11.675, 'eval_steps_per_second': 0.981, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the PEFT model\n",
    "peft_model_evaluation = trainer_peft.evaluate()\n",
    "\n",
    "# Compare the results of the base model and PEFT model\n",
    "print(\"Base Model Evaluation:\")\n",
    "print(base_model_evaluation)\n",
    "\n",
    "print(\"\\nPEFT Model Evaluation:\")\n",
    "print(peft_model_evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339d6ad",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "#### Comparing the results of the base model and the PEFT model:\n",
    "\n",
    "#### Base Model Evaluation:\n",
    "{'eval_loss': 0.548210084438324, 'eval_accuracy': 0.73, 'eval_runtime': 45.873, 'eval_samples_per_second': 10.9, 'eval_steps_per_second': 1.831, 'epoch': 2.0}\n",
    "\n",
    "#### PEFT Model Evaluation:\n",
    "{'eval_loss': 0.5053754448890686, 'eval_accuracy': 0.776, 'eval_runtime': 42.8268, 'eval_samples_per_second': 11.675, 'eval_steps_per_second': 0.981, 'epoch': 4.0}\n",
    "\n",
    "####  Conclusion\n",
    "\n",
    "The evaluation results indicate improvements in the performance of the PEFT (Parameter-Efficient Fine-Tuned) model compared to the Base Model. Specifically, the PEFT Model achieved a lower evaluation loss (0.5054 vs. 0.5482) and a higher accuracy (0.776 vs. 0.73) over the test dataset. Additionally, the PEFT Model demonstrated slightly faster evaluation runtimes with higher samples and steps processed per second. These improvements suggest that the fine-tuning process led to enhancements in both loss reduction and predictive accuracy, showcasing the effectiveness of parameter-efficient fine-tuning in optimizing the model using the rotten_tomatoes dataset for sentiment analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
